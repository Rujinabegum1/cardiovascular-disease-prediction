# -*- coding: utf-8 -*-
"""Cardiovascular Disease Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BSW19ANYEfUA8rlpLDhfBFnl9uUz9ahe

## Import Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from sklearn.preprocessing import StandardScaler

"""## Load Dataset"""

df

"""## Data Analysis"""

# Display first five entries of data

df.head()

# Display last five entries of data

df.tail()

# Display random numbers of data

df.sample(10)

# Show the information of data to find any null value

df.info()

# Show the statistical summary of data

df.describe()

# Show the value of taget column

df['cardio'].value_counts()

# Drop the id column

df=df.drop(['id'],axis=1)
df

# Convert age in year from days

df['age']=(df['age']/365).round(0)
df

# Show correlation between columns

df.corr()

"""#### Check no. of zero values in different columns"""

print('Number of zero values in Age',df[df['age']==0].shape[0])

print('Number of zero values in Gender',df[df['gender']==0].shape[0])

print('Number of zero values in Height',df[df['height']==0].shape[0])

print('Number of zero values in Weight',df[df['weight']==0].shape[0])

print('Number of zero values in Systolic blood pressure',df[df['ap_hi']==0].shape[0])

print('Number of zero values in Diastolic blood pressure',df[df['ap_lo']==0].shape[0])

print('Number of zero values in Cholesterol',df[df['cholesterol']==0].shape[0])

print('Number of zero values in Glucose',df[df['gluc']==0].shape[0])

"""#### Replace zero values with mean of other values in the column"""

df['ap_lo'] = df['ap_lo'].replace(0,df['ap_lo'].mean())
print('Number of zero values in Diastolic blood pressure',df[df['ap_lo']==0].shape[0])

"""## Data Visualization"""

# Count plot of cardio data

f, ax=plt.subplots(1,2,figsize=(10,5))
df['cardio'].value_counts().plot.pie(explode=[0,0.1], autopct='%1.1f%%', ax=ax[0],shadow=True)
ax[0].set_title('cardio')
ax[0].set_ylabel('')
sb.countplot('cardio', data=df, ax=ax[1])
ax[1].set_title('cardio')
N,P = df['cardio'].value_counts()
print('Negative (0): ', N)
print('Positive (0): ', P)
plt.grid()
plt.show()

# Visualize disease rate subjectedly gender

sb.countplot(x='gender',hue='cardio',data=df,palette='pastel',edgecolor=sb.color_palette('dark',n_colors=1))

# Histogram of columns

df.hist(bins=20,figsize=(10,10))
plt.show()

# Correlation analysis

corrmat=df.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(10,10))

#plot heat map

g = sb.heatmap(df[top_corr_features].corr(), annot=True)

"""### Split data into x & y"""

target_name='cardio'

# Separate object for target feature
y = df[target_name]

# Separate object for input feature
x = df.drop(target_name, axis=1)

x.head()

y.head()

"""### Train Test Split data"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)

x_train

y_train

x_test

y_test

"""## Different Classification Algorithms

#### Random Forest Algorithm
"""

from sklearn. ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(x_train, y_train)

print("Train Accuracy of Random Forest Algorithm ", rf.score(x_train,y_train)*100)
print("Test Accuracy score of Random Forest Algorithm ", rf.score(x_test,y_test)*100)

prediction = rf.predict([["50","2","168","62","110","80","1","1","0","0","1"]])
if(prediction !=0):
  print("The person has heart disease")
else:
  print("The person has no heart disease")

prediction = rf.predict([["55","1","156","85","140","90","3","1","0","0","1"]])
if(prediction !=0):
  print("The person has heart disease")
else:
  print("The person has no heart disease")

"""#### Decision Tree Algorithm"""

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(x_train, y_train)

print("Train Accuracy of Decision Tree Algorithm ", dt.score(x_train,y_train)*100)
print("Test Accuracy score of Decision Tree Algorithm ", dt.score(x_test,y_test)*100)

prediction = dt.predict([["50","2","168","62","110","80","1","1","0","0","1"]])
if(prediction !=0):
  print("The person has heart disease")
else:
  print("The person has no heart disease")

prediction = dt.predict([["55","1","156","85","140","90","3","1","0","0","1"]])
if(prediction !=0):
  print("The person has heart disease")
else:
  print("The person has no heart disease")

"""#### Logistic Regression Algorithm"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(solver='liblinear', multi_class='ovr')
lr.fit(x_train, y_train)

print("Train Accuracy of Logistic Regression ", lr.score(x_train,y_train)*100)
print("Test Accuracy score of Logistic Regression ", lr.score(x_test,y_test)*100)

prediction = dt.predict([["50","2","168","62","110","80","1","1","0","0","1"]])
if(prediction !=0):
  print("The person has heart disease")
else:
  print("The person has no heart disease")

prediction = dt.predict([["55","1","156","85","140","90","3","1","0","0","1"]])
if(prediction !=0):
  print("The person has heart disease")
else:
  print("The person has no heart disease")

"""#### K-Nearest Neighbor(KNN) Algorithm"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(x_train, y_train)

print("Train Accuracy of KNN Algorithm ", knn.score(x_train,y_train)*100)
print("Test Accuracy score of KNN Algorithm ", knn.score(x_test,y_test)*100)

prediction = dt.predict([["50","2","168","62","110","80","1","1","0","0","1"]])
if(prediction !=0):
  print("The person has heart disease")
else:
  print("The person has no heart disease")

prediction = dt.predict([["55","1","156","85","140","90","3","1","0","0","1"]])
if(prediction !=0):
  print("The person has heart disease")
else:
  print("The person has no heart disease")

"""#### Naive-Bayes Algorithm"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(x_train, y_train)

print("Train Accuracy of Naive-Bayes Algorithm ", nb.score(x_train,y_train)*100)
print("Test Accuracy score of Naive-Bayes Algorithm ", nb.score(x_test,y_test)*100)

prediction = nb.predict([["50","2","168","62","110","80","1","1","0","0","1"]])
if(prediction !=0):
  print("The person has heart disease")
else:
  print("The person has no heart disease")

prediction = nb.predict([["55","1","156","85","140","90","3","1","0","0","1"]])
if(prediction !=0):
  print("The person has heart disease")
else:
  print("The person has no heart disease")

"""## Predicitng Outcome"""

# Prediction on test using random forest

rf_pred = rf.predict(x_test)

# Prediction on test using decision tree

dt_pred = dt.predict(x_test)

# Prediction on test using logistic regression

lr_pred = lr.predict(x_test)

# Prediction on test using KNN

knn_pred = knn.predict(x_test)

# Prediction on test using naive bayes

nb_pred = nb.predict(x_test)

"""## Confusion Matrix

#### Random Forest Algorithm
"""

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
cm = confusion_matrix(y_test, rf_pred)

print('TN {}'.format(cm[0,0]))
print('FP {}'.format(cm[0,1]))
print('FN {}'.format(cm[1,0]))
print('TP {}'.format(cm[1,1]))
print('Accuracy rate {}'.format(np.divide(np.sum([cm[0,0], cm[1,1]]), np.sum(cm))*100))
print('Misclassification rate {}'.format(np.divide(np.sum([cm[0,1], cm[1,0]]), np.sum(cm))*100))

sb.heatmap(confusion_matrix(y_test, rf_pred), annot=True,fmt="d")

"""#### Decision Tree Algorithm"""

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
cm = confusion_matrix(y_test, dt_pred)

print('TN {}'.format(cm[0,0]))
print('FP {}'.format(cm[0,1]))
print('FN {}'.format(cm[1,0]))
print('TP {}'.format(cm[1,1]))
print('Accuracy rate {}'.format(np.divide(np.sum([cm[0,0], cm[1,1]]), np.sum(cm))*100))
print('Misclassification rate {}'.format(np.divide(np.sum([cm[0,1], cm[1,0]]), np.sum(cm))*100))

sb.heatmap(confusion_matrix(y_test, dt_pred), annot=True,fmt="d")

"""#### Logistic Regretion Algorithm"""

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
cm = confusion_matrix(y_test, lr_pred)

print('TN {}'.format(cm[0,0]))
print('FP {}'.format(cm[0,1]))
print('FN {}'.format(cm[1,0]))
print('TP {}'.format(cm[1,1]))
print('Accuracy rate {}'.format(np.divide(np.sum([cm[0,0], cm[1,1]]), np.sum(cm))*100))
print('Misclassification rate {}'.format(np.divide(np.sum([cm[0,1], cm[1,0]]), np.sum(cm))*100))

sb.heatmap(confusion_matrix(y_test, lr_pred), annot=True,fmt="d")

"""#### K-Nearest Neighbor(KNN) Algorithm"""

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
cm = confusion_matrix(y_test, knn_pred)

print('TN {}'.format(cm[0,0]))
print('FP {}'.format(cm[0,1]))
print('FN {}'.format(cm[1,0]))
print('TP {}'.format(cm[1,1]))
print('Accuracy rate {}'.format(np.divide(np.sum([cm[0,0], cm[1,1]]), np.sum(cm))*100))
print('Misclassification rate {}'.format(np.divide(np.sum([cm[0,1], cm[1,0]]), np.sum(cm))*100))

sb.heatmap(confusion_matrix(y_test, knn_pred), annot=True,fmt="d")

"""#### Naive-Bayes Algorithm"""

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
cm = confusion_matrix(y_test, nb_pred)

print('TN {}'.format(cm[0,0]))
print('FP {}'.format(cm[0,1]))
print('FN {}'.format(cm[1,0]))
print('TP {}'.format(cm[1,1]))
print('Accuracy rate {}'.format(np.divide(np.sum([cm[0,0], cm[1,1]]), np.sum(cm))*100))
print('Misclassification rate {}'.format(np.divide(np.sum([cm[0,1], cm[1,0]]), np.sum(cm))*100))

sb.heatmap(confusion_matrix(y_test, nb_pred), annot=True,fmt="d")

